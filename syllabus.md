---
layout: page
title: Course Syllabus
---

## Conceptual learning objectives

At the end of the workshop, students will be able to . . . 

-	Conceptually understand all components of a linear mixed model (LMM), including: 
  +	Fixed effects
  +	Random intercepts and random slopes
  +	Estimated marginal means
- Understand the difference between a linear mixed model (LMM) and generalized linear mixed model (GLMM)
-	Interpret the output of a LMM and GLMM

## Practical learning objectives

At the end of the workshop, students will be able to . . .

- Read data into R
- Do simple manipulations of R data frames
- Use the R modeling package **lme4** to fit LMM and GLMM models
-	Generate predictions from a fitted model, including estimated marginal means
-	Test specific hypotheses with contrasts

## R packages we will learn about

-	“tidyverse” packages especially **readr**, **dplyr**, and **tidyr** (read and manipulate data)
-	**lme4** (fit models)
- **lmerTest** (do ANOVA tests on mixed models)
- **easystats** (make diagnostic plots to test model assumptions)
-	**emmeans** (estimate treatment effects and test hypotheses)
-	**ggplot2** (make publication-quality graphics)

## Note on general versus generalized models, and Bayesian versus classical statistics

Based on the poll results, it seems that most students taking this course will need to spend some time learning the basics of R before we get into the statistics. Therefore I think it will not be feasible to cover generalized linear models or Bayesian statistics in this workshop. We will focus on R basics and start with simpler LMM models. I will plan a future workshop or series of workshops on generalized linear mixed models, and on Bayesian statistics.

