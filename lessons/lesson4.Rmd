---
title: "Lesson 4: Going further with mixed models"
author: "Quentin D. Read"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: 
  html_document:
    toc: true
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = TRUE, warning = TRUE)
```

# Learning objectives

At the end of this lesson, students will ...

- Fit a linear mixed model with crossed and nested random effects.
- Fit a linear mixed model with a transformed response variable.
- Fit a generalized linear mixed model to binary outcome data.
- Fit a generalized linear mixed model to count outcome data.

# Nested random effects

For this next example, we are going to use a dataset with results from a study of conservation agriculture practices (data hosted on [Ag Data Commons](https://data.nal.usda.gov/dataset/regionally-adapted-implementation-conservation-agriculture-delivers-rapid-improvements-soil-properties-associated-crop-yield-stability)). In this study, the experimental treatments were two different tillage systems crossed with presence or absence of rye cover crop. The original dataset contains results for both maize and soybean yields but I am giving you only the maize yield data for simplicity.


# Load some sample data

We are going to use some data from the **agridat** package, which has lots of example datasets from agricultural science. You can either load the example data from the package directly using `data()`, or read it in from a CSV in the `datasets` folder. Here are both ways of doing it.

```{r}
library(tidyverse)
library(lmerTest)

```

# Random slope models

Imagine we are measuring cash crop yield in a bunch of plots where two different cover crops have been grown. The experiment is set up with paired plots so that every plot with cover crop A is adjacent to a plot that receives cover crop B. There might be an underlying, unmeasured gradient of soil fertility in our study area. Plots where the "baseline" soil fertility is high are probably going to have higher yield than low-fertility plots, even if the effect of the cover crop treatment is about the same across all the plots. We've already seen how to account for this by fitting random intercepts. **The intercepts for each plot are modeled as if they are drawn randomly from a (normal) distribution**.

```{r, echo = FALSE, message = FALSE}
library(tidyverse)

set.seed(314)
fert <- rnorm(5)
fertdat <- data.frame(plot_id = 1:5, fert = fert)
fakedat <- expand.grid(plot_id = 1:5, cover_crop = c('A', 'B')) %>%
  left_join(fertdat) %>%
  mutate(yield = 5 + (cover_crop == 'B') * 2 + fert)

ggplot(fakedat, aes(x = cover_crop, y = yield, group = plot_id, label = plot_id)) +
  geom_line() +
  geom_point(shape = 21, size = 6, fill = 'white') +
  geom_text() +
  theme_classic() +
  scale_x_discrete(expand = c(0.05, 0.05), name = 'cover crop')
```

This plot shows how we would model this situation: all the lines connecting plots from the same pair are parallel. They have different (random) intercepts but the same slopes. This allows us to account for whatever effects unmeasured environmental variables, be it soil fertility or anything else, might have on the yield regardless of the cover crop. For example plot 2 might have higher soil fertility or otherwise more favorable environmental conditions, so it has higher yield in both cover crop treatments.

But what if the *effect* of the treatment itself depends on the plot? For example, if the underlying soil fertility is high, we might expect that the yield effect due to cover crop will not be very big ... the high fertility will cause high yield regardless of cover crop. But there may be some random variation around that pattern. In that case, we would want to assume that **both the intercepts and the treatment effect coefficients are drawn randomly from (normal) distribution**. Regardless of whether the predictor variable is continuous or categorical, fixed effect coefficients other than the intercept are referred to as "slopes." So we would call this a random-slope model (or to be more verbose, a random-intercept random-slope model).

```{r, echo = FALSE}
fakedat$yield[6:10] <- fakedat$yield[6:10] + c(0.6, -1.6, -0.5, 0.2, -1.2)
ggplot(fakedat, aes(x = cover_crop, y = yield, group = plot_id, label = plot_id)) +
  geom_line() +
  geom_point(shape = 21, size = 6, fill = 'white') +
  geom_text() +
  theme_classic() +
  scale_x_discrete(expand = c(0.05, 0.05), name = 'cover crop')
```

The same logic applies if the predictor variable is continuous, instead of a discrete variable with two different levels like in our example above. For instance instead of cover crop treatment we might have biochar amendment applied in a regression design at levels 0, 1, 2, 3, 4, and 5 tons/hectare. The model would be set up in the same way.

# Random slope model: categorical predictor variable

# Random slope model: continuous predictor variable

# Generalized linear mixed models

Taking the log transformation of the response variable before fitting the model is a good solution for many types of data. However it won't always work. INSERT MORE TEXT HERE

- Count data (Poisson GLMM)
- Binary outcome data (Logistic GLMM)

- Show how the residuals cannot be normally distributed for these data
- Discuss log link for Poisson, logit or log odds link for logistic regression

- Show an example of each

- We can set up the model with all the same kinds of fixed and random effects as in plain vanilla linear mixed models. For example, we can have continuous and categorical predictors, interactions, crossed or nested random effects, random intercepts and/or random slopes.

# Hey! What about ...

- These are only a little bit of what you can do. I don't have time to cover all GLMM types in this workshop.
- glmer() doesn't have all the possibilities
- Other common ones are beta-regression, where the response variable is a probability or proportion bounded between 0 and 1
- Cumulative logistic mixed model is another common case, where the response variable is a categorical outcome with more than two possibilities
  + For example a choice trial where insects are released into an olfactometer and may go down one of four arms where different odor attractants are found.
  
- The Bayesian modeling packages **brms** and **rstanarm** are also great alternatives that I would recommend looking into. I'm going to do a workshop on **brms** soon.

# Hey! What about ...

- Repeated measures designs
- Spatial autocorrelation
- Overdispersion in count data
- Different types of random effects (G-side versus R-side) and error structures

These are "advanced topics" in mixed modeling. They are out of scope for this workshop. 